The main configuration file for the Dynamic Partitioning is the
dynpart.conf json file.

json format does not allow comments in it. This document describes the
configuration entries.

See below an example configuration dynpart.conf
(sensitive information altered) with inline description.
Note that comments are not allowed by json syntax, so
they are only meant for documentation purpose.
####################

{
#auth section for Openstack user/project
"auth": {
"USERNAME":"admin",
"PASSWORD":"****************",
"PROJECT_ID":"admin",
"AUTH_URL":"http://131.154.x.y:5000/v2.0",
"USERNAME_d":"demo",
"PASSWORD_d":"****************",
"PROJECT_ID_d":"demo"
},

#log section. The path must exists on the machine running the dynpart
# scripts (p_switch.py, p_driver.py)

"logging": {
"log_dir": "/var/log/indigo/dynpart/",
"log_file": "dynpart.log"
},


# switch section.
# The core configuration section
# 

"switch": {
# batch_cloud_json: this represents the Dynamic Partition Status
# it must be readable by all nodes (Compute Nodes and Worker Nodes)
"batch_cloud_json":"/usr/share/lsf/var/tmp/cloudside/farm.json",

# mcjobs_r: fullpath to an auxiliary program, whose output "rj_file"
# is used by p_driver.py. 
#
"mcjobs_r": "/usr/share/lsf/conf/scripts/dynpart/mcjobs_r",
"rj_file": "/usr/share/lsf/var/tmp/batchside/mcjobs_r.out",

#
# ttl_period: When a Compute Node is selected for migration
# from Cloud to Batch, living VMs are to be removed before the
# role switching can happen. This task should be in charge to
# the cloud project using the VMs.
# Alternatively, a Time To Live can be defined, after that the VMs
# are destroyed by the partition manager.
#
"ttl_period":"300"
},

#
# machine_job_feature: the above ttl_period value is written
# into a TTL_filepath directory, whose name matches the CNs name.
# A TTL_ENV_VAR environment variable is also set
# with the full pathname of the file
#

"machine_job_feature": {
"TTL_filepath":"/usr/share/lsf/var/tmp/cloudside",
"TTL_ENV_VAR":"JOBFEATURES"
},


# VM section Only used by integration tools (such as
# create_instances.py) to test functionalities on a fresh install.
# This helps to simulate the workload of a cloud project

"VM_conf": {
"image":"Fedora22",
"flavor":"m1.large",
"keyname":"demokey",
"max_retries": 5,
"sleeptime": 5
},

# batch_submitter: batch section only used by integration tools (such
# as submitter_demo.py) to test functionalities on a fresh install.
# This helps to simulate the workload of a cloud project.  These are
# parameters for the submitter_demo.py tool, which are used to submit
# sleep jobs to a named queue. the tool submit jobs until max_pend are
# queued, then keeps submitting again when less then min_pend jobs are
# queued. Each job takes a random sleep time with avg_sleep seconds on
# average. After each submission cycle the submitter sleeps for nap
# seconds.

"batch_submitter": {
"cmd_sleep": 10,
"queue": "short",
"max_pend": 300,
"min_pend": 50,
"avg_sleep": 280,
"nap": 5
}

}



